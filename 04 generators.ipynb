{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generators\n",
    "\n",
    "\n",
    "## A shortcut for constructing custom iterators\n",
    "\n",
    "Let's start by examining how to build an iterator that yields the [Fibonacci numbers](https://en.wikipedia.org/wiki/Fibonacci_number).\n",
    "As a refresher, the instructions for computing the $n$th Fibonacci number are\n",
    "\n",
    "$$F_1 = 0 \\\\\n",
    "F_2 = 1 \\\\\n",
    "F_n = F_{n-1} + F_{n-2}$$\n",
    "\n",
    "To construct this iterator, we need to implement the iterator protocol:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FibNumMaker():\n",
    "    def __init__(self):\n",
    "        # Instantiate the iterator with initial states 0 and 1\n",
    "        self.last, self.curr = 0, 1\n",
    "\n",
    "    def __iter__(self):\n",
    "        # Enable the iterator to be compatible with for loops\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        # Determine and yield the subsequent item\n",
    "        temp = self.curr\n",
    "        self.curr += self.last  \n",
    "        self.last = temp              \n",
    "        return temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's difficult to ignore how much boilerplate code is involved in the iterator protocol. Python has always prided itself on being highly readable and concise; not surprisingly, there's an easier way to create our own iterators.\n",
    "\n",
    "### Using generator functions\n",
    "\n",
    "You may have noticed whenever we referred to retrieving the subsequent item from an iterator, we used the term *yield*&mdash;that was no arbitrary choice of words. It turns out that `yield` is a keyword linked to another method for building iterators called a **generator function**. \n",
    "\n",
    "The best way to understand how to use a generator function is to see one in action. Let's implement one that creates an iterator that successively yields a sequence of three numbers: 10, 20 and 30."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An example of a generator function\n",
    "def gen_func():\n",
    "    print('First item')\n",
    "    yield 10\n",
    "    print('Second item')\n",
    "    yield 20\n",
    "    print('Third item')\n",
    "    yield 30\n",
    "    print('No more items left!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To produce an iterator, we call the generator function and assign it to an object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce an iterator\n",
    "seq = gen_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We call `next()` on the iterator to yield its subsequent items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First item\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yield the subsequent item\n",
    "next(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second item\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Third item\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "StopIteration",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9b1a8856b3da>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mStopIteration\u001b[0m: "
     ]
    }
   ],
   "source": [
    "next(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look familiar? We see that `seq` behaved exactly like an iterator built using an iterator protocol; once `seq` was exhausted, it even raised a `StopIteration` exception! An iterator created by a generator function is called a **generator**, but it operates in a similar manner to an iterator created by an iterator protocol. The major difference lies within the construction procedure so let's dive into the generator function and the `yield` keyword.\n",
    "\n",
    "### How to use the yield keyword\n",
    "\n",
    "In an iterator protocol, we used class attributes to hold state and determine the next item. In a generator function, this responsibility is delegated to the `yield` keyword.\n",
    "\n",
    "In the above example, we produced the generator `seq` using the generator function `gen_func()`. When we call `next()` on the generator to yield its subsequent item, here is what's going on behind the scenes:\n",
    "\n",
    "1. Run any lines of code in the generator function, such as the `print()` function in our example, until we hit a `yield` statement\n",
    "2. Return the value or variable dictated by the `yield` statement\n",
    "3. Pause the generator function and relinquish control\n",
    "\n",
    "Upon subsequent calls to `next()` on the generator, we resume where we left off in the generator function and continue to run any lines of code until we hit another `yield` statement, and thus repeating the process. If there are no more `yield` statements left in the generator function, calling `next()` raises a `StopIteration` exception, which indicates we've *exhausted* the generator. Clearly, there's quite a few things going on in the background, but the `yield` statement does a terrific job delineating the generator's next item.\n",
    "\n",
    "Unlike a traditional function that *always* starts at its first line after being called, a generator function resembles \"a function that remembers its place\"; the `yield` statement serves as a bookmark of sorts. **In fact, the presence of a `yield` statement concretely distinguishes a generator function from a traditional function.** \n",
    "\n",
    "One reason generators can be challenging to grasp is because the generator function is doing two things at once:\n",
    "\n",
    "1. Produce a generator\n",
    "2. Determine and yield the subsequent item in an already produced generator\n",
    "\n",
    "The first role is equivalent to the `__init__()` method of the iterator protocol; calling a generator function produces a new generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce another generator\n",
    "seq = gen_func()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second role is equivalent to the `__next__()` method of the iterator protocol; calling `next()` on a generator yields its subsequent item as dictated by the `yield` statements within the generator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First item\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Yield the subsequent item\n",
    "next(seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the iterator protocol, these two roles were explicitly and distinctly defined, but a generator function achieves the same result while doing away with the boilerplate code. For anyone implementing iterator protocols, generator functions are a godsend! On the other hand, if you approach generator functions and the `yield` statement without first understanding [how iterators and the iterator protocol work](http://machinemadephd.com/posts/understanding-iterators/), these constructs can be very perplexing.\n",
    "\n",
    "## Infinite generators\n",
    "\n",
    "We were able to produce infinite iterators by modifying the iterator protocol; similarly, we can tweak a generator function to produce **infinite generators**. Let's demonstrate by converting our iterator protocol for Fibonacci numbers into a generator function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fib_genfunc():\n",
    "    last, curr = 0, 1\n",
    "    while True:\n",
    "        yield curr\n",
    "        last, curr = curr, last + curr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're employing two tricks in this generator function. First, we ensure that we never run out `yield` statements by incorporating an infinite `while` loop. Second, since Python handles assignment statements from left to right, we don't need to utilize a temporary variable as we did in the iterator protocol. The power concealed in these few lines of code is boggling; a truly phenomenal example of the elegance of generators.\n",
    "\n",
    "Let's now produce a generator using `fib_genfunc()` and display the first 50 Fibonacci numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987 1597 2584 4181 6765 10946 17711 28657 46368 75025 121393 196418 317811 514229 832040 1346269 2178309 3524578 5702887 9227465 14930352 24157817 39088169 63245986 102334155 165580141 267914296 433494437 701408733 1134903170 1836311903 2971215073 4807526976 7778742049 12586269025 "
     ]
    }
   ],
   "source": [
    "# Produce a generator\n",
    "fib_seq = fib_genfunc()\n",
    "\n",
    "# Yield the first 50 items\n",
    "for _ in range(50):\n",
    "    print(next(fib_seq), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could also get clever and provide the generator function a parameter that governs the maximum value that can be yielded by the generator. In turn, this provides us with granular control of infinite generators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fib_genfunc2(limit):\n",
    "    last, curr = 0, 1\n",
    "    while curr < limit:\n",
    "        yield curr\n",
    "        last, curr = curr, last + curr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, we can use `fib_genfunc2()` to produce a generator that yields every Fibonacci number below 1 million."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 2 3 5 8 13 21 34 55 89 144 233 377 610 987 1597 2584 4181 6765 10946 17711 28657 46368 75025 121393 196418 317811 514229 832040 "
     ]
    }
   ],
   "source": [
    "# Produce a generator\n",
    "fib_million = fib_genfunc2(1000000)\n",
    "\n",
    "# Yield all items\n",
    "for item in fib_million:\n",
    "    print(item, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator expressions\n",
    "\n",
    "Believe it or not, there's an even *more* straightforward method for building generators, related to [list comprehensions](https://en.wikipedia.org/wiki/List_comprehension). As a reminder, list comprehensions are a convenient way to construct a customized list object. For example, let's create a list containing the cubes of even integers between 0 and 20 inclusive and display each element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8 64 216 512 1000 1728 2744 4096 5832 8000 "
     ]
    }
   ],
   "source": [
    "cubes_list = [x ** 3 for x in range(21) if x % 2 == 0]\n",
    "\n",
    "for i in cubes_list:\n",
    "    print(i, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we swap out the brackets for parentheses in the list comprehension, we have a **generator expression**, which produces a generator that successively yields the same sequence of numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8 64 216 512 1000 1728 2744 4096 5832 8000 "
     ]
    }
   ],
   "source": [
    "cubes_gen = (x ** 3 for x in range(21) if x % 2 == 0)\n",
    "\n",
    "for i in cubes_gen:\n",
    "    print(i, end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, if we add too many conditions in the generator expression, it can become incomprehensible (a big no-no in idiomatic Python). Therefore, a generator function may be more appropriate for building complex generators. However, whenever we're interested in performing an operation on a sequence or a stream of data, it's typically a better idea to use a generator than first creating a list. For example, let's say we wanted to find the sum of the cubes of even integers below 1 million. Let's first do so using a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124999500000500000000000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Produce a list and compute the sum\n",
    "cubes_list2 = [x ** 3 for x in range(1000000) if x % 2 == 0]\n",
    "\n",
    "sum(cubes_list2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, using a generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124999500000500000000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Produce a generator and compute the sum\n",
    "cubes_gen2 = (x ** 3 for x in range(1000000) if x % 2 == 0)\n",
    "\n",
    "sum(cubes_gen2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both methods get the job done but let's take a peek at the memory footprint of each construct. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4290016"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sys import getsizeof\n",
    "\n",
    "# Compute memory footprint of list\n",
    "getsizeof(cubes_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Compute memory footprint of generator\n",
    "getsizeof(cubes_gen2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see the list taking up dramatically more memory than the generator. In fact, whether the generator were to yield ten or $10^{100}$ numbers, its memory footprint would *always* be 88 bytes! Such is the beauty of [lazy evaluation](https://en.wikipedia.org/wiki/Lazy_evaluation). \n",
    "\n",
    "If wanted to perform the same computation using a generator in a single line of code, here's a tip: the set of parentheses for implementing a generator expression isn't required."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124999500000500000000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(x ** 3 for x in range(1000000) if x % 2 == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, it's very important to note that **a generator expression is *not* a tuple comprehension**. That is, a generator expression yields a generator object, not a tuple object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generator"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cubes_gen2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Built-in iterators and generators\n",
    "\n",
    "Even with all of these convenient shortcuts for producing iterators and generators, Python includes a module called [`itertools`](https://docs.python.org/3/library/itertools.html) that contains some useful prepackaged ones. There's also several ingenious recipes that demonstrate ways to get creative with custom iterators. There's simply way too many to describe here but they're worth browsing through; you'll never know when they could come in handy!\n",
    "\n",
    "In addition, if you're performing data science using the Pandas library, you've probably wondered if there was a simple way to loop over the rows or columns of a DataFrame. The following methods can do the job:\n",
    "\n",
    "- `iterrows()` - produces a generator that loops over the indices and rows of a DataFrame\n",
    "- `iteritems()` - produces a generator that loops over the column labels and columns of a DataFrame\n",
    "\n",
    "By now, you should have an in-depth understanding of iterators and generators, how to build them, and use them effectively. I hope these two posts helped shed light on these abstract constructs and illustrated their utility. At first, I found it quite challenging to wrap my head around iterators and generators, but after appreciating what they can do, they've helped me write cleaner and more efficient code. In fact, now whenever I implement a loop, I'm naturally inclined to think about whether a generator could take its place."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
